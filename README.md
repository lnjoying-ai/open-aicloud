# AiCloud: 面向AI场景的智能PaaS平台

## 🌐 项目简介

**AiCloud** 是一套面向 AI 计算与高性能算力服务的全栈云平台解决方案，专注于为企业、科研机构、AI 开发者提供端到端的算力基础设施和智能化服务能力。  
平台集 **算力资源纳管、智能调度、分布式算力管理、统一数据管理、高速传输、商业化运营、统一运维** 于一体，广泛适用于 AI 训练、推理、大模型微调、大数据分析、高性能计算（HPC）等多样化业务场景。

AiCloud 具备**灵活私有化部署能力**，支持对接**跨区域的数据中心、GPU算力资源池**，帮助用户轻松构建弹性、高效、安全的智算平台。同时，平台提供丰富的 **应用市场和镜像服务**，内置多种 **AI 应用模板和推理服务**，支持用户一键部署，加速 AI 业务上线。

本项目已开放核心能力模块，包括 **分布式算力资源管理、智能调度**，欢迎开发者、企业用户、合作伙伴参与共建，共同打造开放可信的下一代 AI 云基础设施平台。

---

## 💡 为什么选择 AiCloud？

### ✅ 端到端一体化 AI 云平台  
从算力资源纳管、调度、编排，到应用交付、数据管理、商业化运营，91GPU.Cloud 提供覆盖全链路的一体化解决方案，满足企业从基础设施到业务交付的所有需求。
### ✅ 灵活适配多种部署与算力环境  
无论是裸金属、虚拟机、容器，还是多云、跨地域、分布式资源，平台均可灵活对接与统一管理，帮助企业快速构建弹性算力架构。
### ✅ 专为 AI 与高性能计算打造  
深度适配 AI 训练、推理、大模型微调等场景，内置主流 AI 框架与模型库，配备 GPU 专属调度与资源池优化，提升算力利用率与业务交付效率。
### ✅ 高速数据传输与安全隔离保障  
自主研发高速传输协议，突破公网带宽瓶颈，同时全链路数据加密、权限隔离、多副本容灾，保障数据安全与业务连续性。
### ✅ 商业化运营能力与生态赋能  
支持多样化定价、促销管理、供应商分账、客户门户等商业化能力，助力平台化运营与合作生态共赢。
### ✅ 完善的运维与监控体系  
提供全栈监控、智能告警、日志审计等多维运维能力，保障平台稳定可靠运行，降低运维成本与风险。

---

## ⚙️ 核心功能特性

### 🎛️ 全栈算力纳管与资源池化管理
- **多形态算力资源支持**：支持裸金属、虚拟机、GPU/CPU 异构资源的统一纳管与调度，适配多样化算力需求。
- **灵活的网络资源编排**：支持 VPC、子网、EIP、NAT、网络安全组等多维网络隔离与策略配置，提升业务网络安全性与灵活性。
- **统一存储资源池管理**：支持 HDD/SSD/NVMe 存储资源池化管理，提供多副本、RAID、快照、分布式存储接入能力，保障数据高可用。
- **跨区域算力接入与统一调度**：支持多地域算力接入，实现全球资源统一编排、纳管与调度，提升资源利用率和业务连续性。
- **智能检索与推荐**：支持按算力类型、计费类型、地理位置、节点负载、可用性等推荐最佳节点，适配用户多样化的算力需求。

### ⚙️ 智能算力调度与多引擎容器编排
- **原生 Kubernetes 编排兼容**：深度适配 K8s、Docker Compose 等主流容器编排工具，支持跨节点、多集群应用部署。
- **多架构适配能力**：兼容 Docker容器引擎，全面支持 x86、ARM 及国产芯片架构，适应多元硬件环境。
- **丰富的语言与 AI 框架支持**：兼容 Java、Python、Node.js 及 TensorFlow、PyTorch 等主流 AI 框架，助力 AI 应用快速交付。
- **完善的容器生命周期管理**：支持容器的创建、启停、监控、迁移等全生命周期管理，提升容器服务稳定性与弹性。

### 🛒 应用市场
- **预置主流开源大模型与AI应用**：平台内置如 Llama、Gemma、Stable Diffusion 等主流开源大模型和 AI 应用模板，支持用户一键部署，快速搭建训练或推理环境。
- **集成 Nvidia NIM AI 推理服务**：预集成 Nvidia 推出的 NIM AI 推理服务镜像，提供即插即用的企业级 AI 推理能力，降低部署门槛，加速企业 AI 服务上线。
- **自定义应用模板工具**：提供易用的 Compose 模板配置工具，用户可根据自身业务需求，自定义部署脚本并保存为私有或共享模板，提升应用交付效率。
- **一键部署能力**：用户可通过简单的参数配置，快速完成 AI 模型、应用或数据服务的一键部署，大幅降低技术门槛，加快业务上线节奏。

### 🐳 容器镜像服务
- **内置企业级镜像仓库**：提供多项目、多用户隔离的镜像管理能力，支持镜像版本控制、访问权限管理，保障企业内部镜像安全合规。
- **镜像预载与加速分发**：支持将常用镜像预载至节点，减少网络带宽占用，加速应用启动与大规模批量部署。
- **私有与第三方镜像仓库对接**：支持对接企业私有 Harbor、Docker Hub 等第三方镜像仓库，兼容 OCI 标准，满足多源镜像拉取需求。

### ⚡ 统一数据管理与高速传输引擎
- **个人/公共数据空间管理**：支持用户自定义管理模型、数据集、程序包等资源，提升数据共享与交付效率。
- **自研 UDP 高速传输引擎**：基于 UDP 传输协议，支持 TB 级大文件、断点续传、高丢包网络环境下的高速稳定传输。
- **多维安全防护机制**：采用 AES-256 加密、CRC 校验、数据切片技术，全面保障数据传输过程的完整性与安全性。

### 💼 算力运营与商业化支持
- **丰富的算力产品组合**：支持 CPU/GPU/内存/带宽等多种资源套餐组合，满足不同场景下的算力供给需求。
- **灵活的计费与促销策略**：支持包月包年、按量计费、折扣促销等多样化定价模式，帮助平台优化资源变现能力。
- **供应商分账与收益管理**：内置分账结算模块，支持与多方资源供应商合作，自动化收益分配与结算。
- **多角色运营管理门户**：支持客户、供应商、运维人员多角色登录与权限管理，提升平台运营效率与服务体验。

### 🛠️ 智算统一运维平台
- **全栈资源实时监控**：提供服务器 CPU、内存、硬盘、网络、GPU 显存与算力利用率，以及容器、虚拟机等资源的全维度监控能力，保障资源透明可视。
- **智能告警与自动恢复**：支持自定义阈值告警，结合短信、邮件多通道实时通知，帮助运维人员快速响应异常事件。
- **日志与事件审计管理**：集中管理集群、虚拟机、容器、用户操作等多类日志，支持快速检索与分析，提升运维排障效率。
- **多租户资源隔离与权限管理**：内置 IAM 权限管理，支持多角色、多租户资源隔离管理，保障平台多租户业务的安全与稳定运行。

---

## 🧪 快速上手

```bash
# 拉取 aiCloud 安装包
git clone https://github.com/your-org/aiCloud.git
cd aiCloud

# 部署容器服务
./deploy.sh

# 访问平台控制台
http://localhost:8081
```

---

## 推荐部署配置（待完成）

### 📦 基础环境要求

| 组件          | 推荐配置                  |
|---------------|---------------------------|
| 操作系统      | Ubuntu 20.04 / CentOS 7+   |
| 内核版本      | 5.10+                      |
| Docker 版本   | 20.10.x                    |
| Kubernetes    | 1.26+                      |
| Helm 版本     | 3.10+                      |
| Python        | 3.8+                       |
| GPU 驱动      | NVIDIA Driver 525+         |
| CUDA Toolkit  | CUDA 11.8+                 |
| 网络端口      | 80/443/30000-32767（TCP）  |

---

### 🚀 软硬件资源建议

#### 管理节点（Master）
- CPU：8 核心
- 内存：32 GB
- 硬盘：500 GB SSD
- 网络：千兆以上网络接口

#### 计算节点（Compute）
- CPU：16 核心以上
- 内存：64 GB 以上
- 硬盘：1 TB SSD 或 NVMe
- GPU：NVIDIA A100 / RTX 4090 / V100
- 网络：万兆网络或 RoCE 网络（建议）

#### 存储节点（可选）
- CPU：8 核心
- 内存：32 GB
- 存储：10 TB 以上 HDD + SSD 缓存
- 网络：千兆以上网络接口

---

### 🛠️ 可选组件支持

- **分布式存储**：Ceph / MinIO / NFS
- **对象存储**：S3 / MinIO
- **负载均衡**：NGINX / HAProxy
- **日志与监控**：Prometheus + Grafana
- **高速传输组件**：Lnjoying自研 UDP 传输引擎

---

## 📚 文档资源

- **开发者指南**：[Developer Guide](https://your-dev-guide-link)
- **API 文档**：[API Reference](https://your-api-docs-link)
- **系统架构**：[Architecture Overview](https://your-architecture-link)
- **快速入门**：[Quickstart Guide](https://your-quickstart-link)

---

## 🤝 贡献方式

欢迎所有开发者参与 aiCloud 的构建：

1. Fork 本仓库
2. 创建特性分支 `git checkout -b feature/awesome-feature`
3. 提交代码 `git commit -m 'Add awesome feature'`
4. 推送分支 `git push origin feature/awesome-feature`
5. 发起 Pull Request

📌 详细贡献说明：[Contributing Guide](https://your-contribution-guide)

---

## 🪪 License

本项目采用 **Apache 2.0** 开源许可证，详情见 [LICENSE](LICENSE)

---

## 📣 联系我们

- 官网：[https://91gpu.cloud](https://91gpu.cloud)
- 邮箱：service@lnjoying.com
- 社区：微信交流群